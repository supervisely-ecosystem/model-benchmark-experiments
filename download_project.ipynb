{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ../data/coco_eval/dt_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_dataset_id = 88850\n",
    "dt_dataset_id = 89542\n",
    "save_path = '../data/coco_eval'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "{\"message\": \"progress\", \"event_type\": \"EventType.PROGRESS\", \"subtask\": \"Downloading dataset: 'val'\", \"current\": 0, \"total\": 200, \"timestamp\": \"2024-04-16T06:31:27.298Z\", \"level\": \"info\"}\n",
      "{\"message\": \"progress\", \"event_type\": \"EventType.PROGRESS\", \"subtask\": \"Downloading dataset: 'val'\", \"current\": 50, \"total\": 200, \"timestamp\": \"2024-04-16T06:31:36.784Z\", \"level\": \"info\"}\n",
      "{\"message\": \"progress\", \"event_type\": \"EventType.PROGRESS\", \"subtask\": \"Downloading dataset: 'val'\", \"current\": 100, \"total\": 200, \"timestamp\": \"2024-04-16T06:31:45.885Z\", \"level\": \"info\"}\n",
      "{\"message\": \"progress\", \"event_type\": \"EventType.PROGRESS\", \"subtask\": \"Downloading dataset: 'val'\", \"current\": 150, \"total\": 200, \"timestamp\": \"2024-04-16T06:31:55.068Z\", \"level\": \"info\"}\n",
      "{\"message\": \"progress\", \"event_type\": \"EventType.PROGRESS\", \"subtask\": \"Downloading dataset: 'val'\", \"current\": 200, \"total\": 200, \"timestamp\": \"2024-04-16T06:32:03.788Z\", \"level\": \"info\"}\n"
     ]
    }
   ],
   "source": [
    "import supervisely as sly\n",
    "import json\n",
    "import os\n",
    "\n",
    "api = sly.Api()\n",
    "\n",
    "gt_project_id = api.dataset.get_info_by_id(gt_dataset_id).project_id\n",
    "dt_project_id = api.dataset.get_info_by_id(dt_dataset_id).project_id\n",
    "dataset_name = api.dataset.get_info_by_id(gt_dataset_id).name\n",
    "\n",
    "# Download project\n",
    "# sly.download(api, gt_project_id, save_path+\"/gt_dataset\", dataset_ids=[gt_dataset_id], log_progress=True)\n",
    "sly.download(api, dt_project_id, save_path+\"/dt_dataset\", dataset_ids=[dt_dataset_id], log_progress=True)\n",
    "gt_project = sly.read_project(save_path+\"/gt_dataset\")\n",
    "dt_project = sly.read_project(save_path+\"/dt_dataset\")\n",
    "\n",
    "# Get datasets\n",
    "gt_dataset : sly.Dataset = next(iter(gt_project.datasets))\n",
    "dt_dataset : sly.Dataset = next(iter(dt_project.datasets))\n",
    "assert sorted(gt_dataset.get_items_names()) == sorted(dt_dataset.get_items_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion to COCO format completed and files saved.\n"
     ]
    }
   ],
   "source": [
    "def create_category_id_map(meta: sly.ProjectMeta):\n",
    "    category_id_map = {}\n",
    "    for i, obj_class in enumerate(meta.obj_classes):\n",
    "        category_id_map[obj_class.name] = i + 1\n",
    "    return category_id_map\n",
    "\n",
    "def dataset_to_coco(dataset: sly.Dataset, category_id_map, is_prediction, meta):\n",
    "    coco_data = {\n",
    "        \"images\": [],\n",
    "        \"annotations\": [],\n",
    "        \"categories\": []\n",
    "    }\n",
    "    annotation_id = 1\n",
    "    image_id_map = {name: i for i, name in enumerate(sorted(dataset.get_items_names()))}\n",
    "\n",
    "    # Add category information to COCO data\n",
    "    for category_name, category_id in category_id_map.items():\n",
    "        coco_data[\"categories\"].append({\"id\": category_id, \"name\": category_name})\n",
    "\n",
    "    # Processing annotations\n",
    "    for name in sorted(dataset.get_items_names()):\n",
    "        ann : sly.Annotation = dataset.get_ann(name, meta)\n",
    "        image_id = image_id_map[name]\n",
    "        coco_data[\"images\"].append({\n",
    "            \"id\": image_id,\n",
    "            \"file_name\": dataset.get_img_path(name),\n",
    "            \"width\": ann.img_size[1],\n",
    "            \"height\": ann.img_size[0]\n",
    "        })\n",
    "        for label in ann.labels:\n",
    "            if label.obj_class.geometry_type == sly.Rectangle:\n",
    "                category_id = category_id_map[label.obj_class.name]\n",
    "                bbox : sly.Rectangle = label.geometry.to_bbox()\n",
    "                annotation = {\n",
    "                    \"id\": annotation_id,\n",
    "                    \"image_id\": image_id,\n",
    "                    \"category_id\": category_id,\n",
    "                    \"bbox\": [bbox.left, bbox.top, bbox.width, bbox.height],\n",
    "                    \"area\": bbox.width * bbox.height,\n",
    "                    \"iscrowd\": 0\n",
    "                }\n",
    "                \n",
    "                if is_prediction:\n",
    "                    # Extract confidence score from the tag\n",
    "                    score = label.tags.get(\"confidence\").value\n",
    "                    annotation[\"score\"] = float(score)\n",
    "                \n",
    "                coco_data[\"annotations\"].append(annotation)\n",
    "                annotation_id += 1\n",
    "\n",
    "    return coco_data\n",
    "\n",
    "# Meta\n",
    "meta = gt_project.meta\n",
    "\n",
    "# Create a consistent category ID mapping for both datasets\n",
    "category_id_map = create_category_id_map(meta)\n",
    "\n",
    "# Convert datasets to COCO format with consistent category IDs\n",
    "cocoGt = dataset_to_coco(gt_dataset, category_id_map, False, meta)\n",
    "cocoDt = dataset_to_coco(dt_dataset, category_id_map, True, meta)\n",
    "\n",
    "# assert image ids are the same\n",
    "assert len(cocoGt[\"images\"]) == len(cocoDt[\"images\"])\n",
    "for i in range(len(cocoGt[\"images\"])):\n",
    "    assert os.path.basename(cocoGt[\"images\"][i][\"file_name\"]) == os.path.basename(cocoDt[\"images\"][i][\"file_name\"])\n",
    "    assert cocoGt[\"images\"][i][\"id\"] == cocoDt[\"images\"][i][\"id\"]\n",
    "\n",
    "# Optionally save to JSON\n",
    "with open('cocoGt.json', 'w') as f:\n",
    "    json.dump(cocoGt, f)\n",
    "with open('cocoDt.json', 'w') as f:\n",
    "    json.dump(cocoDt['annotations'], f)\n",
    "\n",
    "print(\"Conversion to COCO format completed and files saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.05s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.188\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.227\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.213\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.047\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.268\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.254\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.254\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.055\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.363\n"
     ]
    }
   ],
   "source": [
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "\n",
    "# Load ground truth data\n",
    "cocoGt=COCO(\"cocoGt.json\")\n",
    "\n",
    "# Load prediction data\n",
    "cocoDt=cocoGt.loadRes(\"cocoDt.json\")\n",
    "\n",
    "# Initialize COCOeval object\n",
    "cocoEval = COCOeval(cocoGt, cocoDt, 'bbox')\n",
    "\n",
    "# Evaluate on a subset of images (optional)\n",
    "# cocoEval.params.imgIds = [5]  # Remove this line to evaluate on all images\n",
    "\n",
    "# Run evaluation\n",
    "cocoEval.evaluate()\n",
    "cocoEval.accumulate()\n",
    "cocoEval.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtdetr-50 ep200: 0.177\n",
    "rtdetr-50 ep60: 0.213\n",
    "rtdetr-50 EMA ep60: 0.189\n",
    "rtdetr-50 MODEL ep60: 0.188"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
